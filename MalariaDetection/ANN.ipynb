{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc48d88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-27 12:26:13.902403: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-27 12:26:13.902830: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-27 12:26:13.905328: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-27 12:26:13.911645: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745736973.922882   14553 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745736973.925944   14553 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1745736973.934641   14553 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745736973.934657   14553 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745736973.934658   14553 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745736973.934659   14553 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-27 12:26:13.937657: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Lists to store image data\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Function to insert images and labels\n",
    "def insert(folder_path, label):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            img = Image.open(img_path).convert('RGB')  # Ensure RGB\n",
    "            img = img.resize((32, 32))  # Resize to 32x32\n",
    "            img = np.array(img)\n",
    "            data.append(img)\n",
    "            labels.append(label)\n",
    "\n",
    "# Insert infected and uninfected images\n",
    "insert(\"Image/img/para\", 1)\n",
    "insert(\"Image/img/uni\", 0)\n",
    "\n",
    "# Shuffle data and labels together\n",
    "data, labels = shuffle(data, labels, random_state=42)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Normalize pixel values\n",
    "data = data / 255.0\n",
    "\n",
    "# Flatten images\n",
    "data = data.reshape(data.shape[0], -1)  # (num_samples, 3072)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b43467d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jk/Semester3/MalariaDetection/myenv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-04-27 12:27:02.153213: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_shape=(3072,)))  # Bigger first layer\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))  # New extra small layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93c43665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.6956 - loss: 0.5786 - val_accuracy: 0.6943 - val_loss: 0.5838\n",
      "Epoch 2/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.6980 - loss: 0.5775 - val_accuracy: 0.6887 - val_loss: 0.5871\n",
      "Epoch 3/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.6996 - loss: 0.5760 - val_accuracy: 0.6818 - val_loss: 0.6004\n",
      "Epoch 4/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7011 - loss: 0.5714 - val_accuracy: 0.6831 - val_loss: 0.5966\n",
      "Epoch 5/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.6958 - loss: 0.5765 - val_accuracy: 0.6970 - val_loss: 0.5827\n",
      "Epoch 6/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7058 - loss: 0.5719 - val_accuracy: 0.6929 - val_loss: 0.5842\n",
      "Epoch 7/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7048 - loss: 0.5667 - val_accuracy: 0.6874 - val_loss: 0.5901\n",
      "Epoch 8/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7035 - loss: 0.5661 - val_accuracy: 0.6959 - val_loss: 0.5783\n",
      "Epoch 9/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7081 - loss: 0.5655 - val_accuracy: 0.7017 - val_loss: 0.5756\n",
      "Epoch 10/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7095 - loss: 0.5642 - val_accuracy: 0.6939 - val_loss: 0.5798\n",
      "Epoch 1/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7079 - loss: 0.5658 - val_accuracy: 0.6983 - val_loss: 0.5794\n",
      "Epoch 2/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7030 - loss: 0.5681 - val_accuracy: 0.6921 - val_loss: 0.5792\n",
      "Epoch 3/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7133 - loss: 0.5569 - val_accuracy: 0.7001 - val_loss: 0.5795\n",
      "Epoch 4/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7062 - loss: 0.5653 - val_accuracy: 0.6974 - val_loss: 0.5784\n",
      "Epoch 5/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7067 - loss: 0.5627 - val_accuracy: 0.6929 - val_loss: 0.5837\n",
      "Epoch 6/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7086 - loss: 0.5612 - val_accuracy: 0.7010 - val_loss: 0.5735\n",
      "Epoch 7/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7114 - loss: 0.5600 - val_accuracy: 0.6988 - val_loss: 0.5726\n",
      "Epoch 8/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7157 - loss: 0.5570 - val_accuracy: 0.7017 - val_loss: 0.5736\n",
      "Epoch 9/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7120 - loss: 0.5545 - val_accuracy: 0.6979 - val_loss: 0.5731\n",
      "Epoch 10/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7122 - loss: 0.5609 - val_accuracy: 0.7021 - val_loss: 0.5697\n",
      "Epoch 1/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7088 - loss: 0.5595 - val_accuracy: 0.7025 - val_loss: 0.5805\n",
      "Epoch 2/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7080 - loss: 0.5601 - val_accuracy: 0.7056 - val_loss: 0.5685\n",
      "Epoch 3/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7181 - loss: 0.5514 - val_accuracy: 0.6927 - val_loss: 0.5772\n",
      "Epoch 4/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7170 - loss: 0.5574 - val_accuracy: 0.6814 - val_loss: 0.5923\n",
      "Epoch 5/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7168 - loss: 0.5511 - val_accuracy: 0.6881 - val_loss: 0.5851\n",
      "Epoch 6/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7234 - loss: 0.5468 - val_accuracy: 0.7028 - val_loss: 0.5723\n",
      "Epoch 7/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7193 - loss: 0.5486 - val_accuracy: 0.6845 - val_loss: 0.5928\n",
      "Epoch 8/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7200 - loss: 0.5507 - val_accuracy: 0.7023 - val_loss: 0.5697\n",
      "Epoch 9/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.7249 - loss: 0.5457 - val_accuracy: 0.7014 - val_loss: 0.5731\n",
      "Epoch 10/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7280 - loss: 0.5423 - val_accuracy: 0.6974 - val_loss: 0.5855\n",
      "Epoch 1/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7261 - loss: 0.5430 - val_accuracy: 0.6881 - val_loss: 0.5909\n",
      "Epoch 2/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7187 - loss: 0.5484 - val_accuracy: 0.6883 - val_loss: 0.5943\n",
      "Epoch 3/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7245 - loss: 0.5463 - val_accuracy: 0.6943 - val_loss: 0.5796\n",
      "Epoch 4/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7242 - loss: 0.5438 - val_accuracy: 0.7008 - val_loss: 0.5762\n",
      "Epoch 5/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.7271 - loss: 0.5403 - val_accuracy: 0.6950 - val_loss: 0.5838\n",
      "Epoch 6/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7197 - loss: 0.5495 - val_accuracy: 0.7019 - val_loss: 0.5684\n",
      "Epoch 7/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7224 - loss: 0.5483 - val_accuracy: 0.6990 - val_loss: 0.5865\n",
      "Epoch 8/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.7214 - loss: 0.5459 - val_accuracy: 0.7039 - val_loss: 0.5700\n",
      "Epoch 9/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.7229 - loss: 0.5458 - val_accuracy: 0.6934 - val_loss: 0.5893\n",
      "Epoch 10/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.7158 - loss: 0.5494 - val_accuracy: 0.7019 - val_loss: 0.5732\n",
      "Epoch 1/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7221 - loss: 0.5453 - val_accuracy: 0.7066 - val_loss: 0.5743\n",
      "Epoch 2/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7279 - loss: 0.5427 - val_accuracy: 0.6997 - val_loss: 0.5795\n",
      "Epoch 3/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7275 - loss: 0.5393 - val_accuracy: 0.6896 - val_loss: 0.5989\n",
      "Epoch 4/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7244 - loss: 0.5414 - val_accuracy: 0.6820 - val_loss: 0.6112\n",
      "Epoch 5/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7233 - loss: 0.5412 - val_accuracy: 0.7061 - val_loss: 0.5750\n",
      "Epoch 6/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7250 - loss: 0.5383 - val_accuracy: 0.7046 - val_loss: 0.5722\n",
      "Epoch 7/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7270 - loss: 0.5363 - val_accuracy: 0.6938 - val_loss: 0.5830\n",
      "Epoch 8/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7290 - loss: 0.5390 - val_accuracy: 0.7057 - val_loss: 0.5696\n",
      "Epoch 9/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7228 - loss: 0.5388 - val_accuracy: 0.7117 - val_loss: 0.5676\n",
      "Epoch 10/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7222 - loss: 0.5399 - val_accuracy: 0.7045 - val_loss: 0.5765\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7010 - loss: 0.5801\n",
      "Test Accuracy: 70.45%\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9dce0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
